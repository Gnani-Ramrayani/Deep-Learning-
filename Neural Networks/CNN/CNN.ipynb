{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f5019f",
   "metadata": {},
   "source": [
    "##Implementation of LesNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469cc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #importing necessary libraries\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.ops import nms\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cce7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)        # C1\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) # S2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)       # C3\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) # S4\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5)     # C5\n",
    "        self.fc1 = nn.Linear(120, 84)                      # F6\n",
    "        self.fc2 = nn.Linear(84, num_classes)              # Output\n",
    "\n",
    "#defining how input flows through the neural network using forward in pytorch\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten, must be flattened before fully connected layers as they accept input as only 1d vector.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09482ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing MNIST dataset to test LeNet5 for classification\n",
    "\n",
    "transform = transforms.Compose([transforms.Pad(2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fc9e61-76f6-4dae-9dfc-c2a140656e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8dcc89-af66-4f92-982f-feebd7480fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [0/60000] Loss: 2.306676\n",
      "Epoch 1 [6400/60000] Loss: 0.419217\n",
      "Epoch 1 [12800/60000] Loss: 0.402976\n",
      "Epoch 1 [19200/60000] Loss: 0.229081\n",
      "Epoch 1 [25600/60000] Loss: 0.130060\n",
      "Epoch 1 [32000/60000] Loss: 0.133388\n",
      "Epoch 1 [38400/60000] Loss: 0.118812\n",
      "Epoch 1 [44800/60000] Loss: 0.081738\n",
      "Epoch 1 [51200/60000] Loss: 0.064917\n",
      "Epoch 1 [57600/60000] Loss: 0.100657\n",
      "Epoch 2 [0/60000] Loss: 0.116946\n",
      "Epoch 2 [6400/60000] Loss: 0.176799\n",
      "Epoch 2 [12800/60000] Loss: 0.051048\n",
      "Epoch 2 [19200/60000] Loss: 0.135149\n",
      "Epoch 2 [25600/60000] Loss: 0.048388\n",
      "Epoch 2 [32000/60000] Loss: 0.099510\n",
      "Epoch 2 [38400/60000] Loss: 0.073915\n",
      "Epoch 2 [44800/60000] Loss: 0.009971\n",
      "Epoch 2 [51200/60000] Loss: 0.071799\n",
      "Epoch 2 [57600/60000] Loss: 0.031409\n",
      "Epoch 3 [0/60000] Loss: 0.084113\n",
      "Epoch 3 [6400/60000] Loss: 0.025427\n",
      "Epoch 3 [12800/60000] Loss: 0.038712\n",
      "Epoch 3 [19200/60000] Loss: 0.014982\n",
      "Epoch 3 [25600/60000] Loss: 0.036547\n",
      "Epoch 3 [32000/60000] Loss: 0.022317\n",
      "Epoch 3 [38400/60000] Loss: 0.027768\n",
      "Epoch 3 [44800/60000] Loss: 0.014418\n",
      "Epoch 3 [51200/60000] Loss: 0.044643\n",
      "Epoch 3 [57600/60000] Loss: 0.009320\n",
      "Epoch 4 [0/60000] Loss: 0.010995\n",
      "Epoch 4 [6400/60000] Loss: 0.010769\n",
      "Epoch 4 [12800/60000] Loss: 0.032472\n",
      "Epoch 4 [19200/60000] Loss: 0.011328\n",
      "Epoch 4 [25600/60000] Loss: 0.003364\n",
      "Epoch 4 [32000/60000] Loss: 0.014224\n",
      "Epoch 4 [38400/60000] Loss: 0.034303\n",
      "Epoch 4 [44800/60000] Loss: 0.007088\n",
      "Epoch 4 [51200/60000] Loss: 0.043271\n",
      "Epoch 4 [57600/60000] Loss: 0.016925\n",
      "Epoch 5 [0/60000] Loss: 0.018130\n",
      "Epoch 5 [6400/60000] Loss: 0.125175\n",
      "Epoch 5 [12800/60000] Loss: 0.047879\n",
      "Epoch 5 [19200/60000] Loss: 0.013986\n",
      "Epoch 5 [25600/60000] Loss: 0.017179\n",
      "Epoch 5 [32000/60000] Loss: 0.015425\n",
      "Epoch 5 [38400/60000] Loss: 0.008899\n",
      "Epoch 5 [44800/60000] Loss: 0.001439\n",
      "Epoch 5 [51200/60000] Loss: 0.016622\n",
      "Epoch 5 [57600/60000] Loss: 0.008186\n",
      "Epoch 6 [0/60000] Loss: 0.005553\n",
      "Epoch 6 [6400/60000] Loss: 0.076752\n",
      "Epoch 6 [12800/60000] Loss: 0.051083\n",
      "Epoch 6 [19200/60000] Loss: 0.053528\n",
      "Epoch 6 [25600/60000] Loss: 0.049481\n",
      "Epoch 6 [32000/60000] Loss: 0.034812\n",
      "Epoch 6 [38400/60000] Loss: 0.003640\n",
      "Epoch 6 [44800/60000] Loss: 0.085378\n",
      "Epoch 6 [51200/60000] Loss: 0.004194\n",
      "Epoch 6 [57600/60000] Loss: 0.009533\n",
      "Epoch 7 [0/60000] Loss: 0.003783\n",
      "Epoch 7 [6400/60000] Loss: 0.006782\n",
      "Epoch 7 [12800/60000] Loss: 0.046305\n",
      "Epoch 7 [19200/60000] Loss: 0.010062\n",
      "Epoch 7 [25600/60000] Loss: 0.005948\n",
      "Epoch 7 [32000/60000] Loss: 0.003830\n",
      "Epoch 7 [38400/60000] Loss: 0.001586\n",
      "Epoch 7 [44800/60000] Loss: 0.000482\n",
      "Epoch 7 [51200/60000] Loss: 0.005214\n",
      "Epoch 7 [57600/60000] Loss: 0.059022\n",
      "Epoch 8 [0/60000] Loss: 0.013095\n",
      "Epoch 8 [6400/60000] Loss: 0.009762\n",
      "Epoch 8 [12800/60000] Loss: 0.005392\n",
      "Epoch 8 [19200/60000] Loss: 0.019513\n",
      "Epoch 8 [25600/60000] Loss: 0.006445\n",
      "Epoch 8 [32000/60000] Loss: 0.000933\n",
      "Epoch 8 [38400/60000] Loss: 0.001614\n",
      "Epoch 8 [44800/60000] Loss: 0.001730\n",
      "Epoch 8 [51200/60000] Loss: 0.006358\n",
      "Epoch 8 [57600/60000] Loss: 0.013995\n",
      "Epoch 9 [0/60000] Loss: 0.000544\n",
      "Epoch 9 [6400/60000] Loss: 0.005370\n",
      "Epoch 9 [12800/60000] Loss: 0.018045\n",
      "Epoch 9 [19200/60000] Loss: 0.004050\n",
      "Epoch 9 [25600/60000] Loss: 0.001232\n",
      "Epoch 9 [32000/60000] Loss: 0.004393\n",
      "Epoch 9 [38400/60000] Loss: 0.051364\n",
      "Epoch 9 [44800/60000] Loss: 0.015024\n",
      "Epoch 9 [51200/60000] Loss: 0.000535\n",
      "Epoch 9 [57600/60000] Loss: 0.014816\n",
      "Epoch 10 [0/60000] Loss: 0.002076\n",
      "Epoch 10 [6400/60000] Loss: 0.012880\n",
      "Epoch 10 [12800/60000] Loss: 0.006953\n",
      "Epoch 10 [19200/60000] Loss: 0.003551\n",
      "Epoch 10 [25600/60000] Loss: 0.002864\n",
      "Epoch 10 [32000/60000] Loss: 0.002378\n",
      "Epoch 10 [38400/60000] Loss: 0.008869\n",
      "Epoch 10 [44800/60000] Loss: 0.001257\n",
      "Epoch 10 [51200/60000] Loss: 0.016026\n",
      "Epoch 10 [57600/60000] Loss: 0.022727\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # Try 2 epochs for a quick test\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch+1} [{batch_idx * len(data)}/{len(train_loader.dataset)}] Loss: {loss.item():.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d75392-9120-44ec-a6f7-56bf63bd6e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.04%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
